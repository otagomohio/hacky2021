[{"uri":"https://otagomohio.github.io/hacky2021/","title":"Hacky Hour 2021","tags":[],"description":"","content":"Hacky Hour 2021 This is a resource for getting help on data analysis. This site will serve as the main base for the Hacky Hour 2021 help session, held monthly during the semester at the University of Otago Anatomy Department tearoom. Check here for announcements of new sessions, information from past sessions, and suggest new topics.\n"},{"uri":"https://otagomohio.github.io/hacky2021/concepts/building_blocks/","title":"Building blocks","tags":[],"description":"","content":"Most bioinformatic methods can be organised into a few basic concepts. I have organised these in terms of how the method influences the sequence files and how it modifies or what information is gathered from them. I use the term \u0026lsquo;sequence file\u0026rsquo; very broadly; it can encompass anything from raw reads to assembled contigs to scaffolds to whole organelle or chromosome assemblies. I have furthur divided these into two main classes: lower-level processes and higher-level processes. These are explained in detail below.\nLower-level building blocks I identify three major types of lower-level processes:\n Pattern searching \u0026ndash; finding patterns within a sequence Mapping \u0026ndash; pairwise alignment of a sequence against a database Clustering \u0026ndash; group together a collection of sequences based on identity  Each of these process types can encompass or be a part of many programs, and be applied to multiple sequence types\u0026ndash;as outlined above. Pattern searching is typical of early steps in most processing of raw reads, and includes adapter and primer removal, as well as quality filtering. However, it also is involved in many downstream processing steps, including searching for coding regions or CG islands on assembled contigs, or repeats across whole genome assemblies. Note that often these searches are looking for patterns based on existing references, such as adapter sequence files or repeat databases, but they can also involve looking for patterns not neccesarily dependent on any external reference, such as start and stop codons along a contig.\nFor Mapping processes, these involve searching whole sequences against some kind of reference database. As with Pattern searching, these can involve a BLAST search of short reads or assembled contigs or aligning RNA reads to a transcriptome. Kraken, HMM\nThese first two processes may seem like the same thing, and indeed they are more or less two sides of the same coin. But because they are usually very separate in pipelines I am keeping them distinct. I distinguish them by what is the subject and what is the object of the search: generally Pattern searching is looking for elements of a database somewhere along a sequence (database is subject, sequence is object), wherease Mapping is searching in a database for whole sequence reads (sequence is subject, database is object). Though for many searches, especially local alignments, matches to only part of the sequence may be found, it is usually the whole sequence that is the search query. Because of the nature of both of these (especially where pattern searching is looking for shorter and often, fragmentary patterns), generally the algorithms used for both are different.\nThe third type, Clustering, involves grouping or clustering a collection of sequences based on similarity. It is only comparing within a group of sequences, and does not generally involve any external references (of course, there are many hybrid clustering approaches that combine mapping and clustering, but often these happen in turn). Clustering methods are found across many bioinformatic pipelines and include kmer counting, OTU clustering (in metabarcoding), and dereplication. I include genome assembly here, though genome assemblies usually involve a wide range of steps, but building larger contigs from alignments of kmers is one of the core approaches. I also include multiple sequence alignment (MSA) here; while it is an alignment method, it is distinct from the Mapping alignment methods described above, as those generally involve pairwise comparisons\u0026ndash;aligning a single query separately to each of many subjects in a database. While a MSA is generated from the simultaneous alignment of multiple sequences\u0026ndash;at heart it is a very different approach.\nHere is a summary table that includes some examples of each method:\n   Pattern searching Mapping Clustering     finding patterns within a sequence pairwise alignment of a sequence against a database group together a collection of sequences based on identity   adapter/primer removal align reads to genome kmer counting   gene prediction BLAST search genome assembly   motif searching HMM search for protein domains dereplication   repeat finder create OTU table multiple sequence alignment         Next level: higher order processes From the basic processes, there are higher level methods that make statistical inferences about the results of the lower-level building blocks. For example, a phylogenetic analysis will try to infer relationships among samples in a multiple sequence alignment. Likewise, a principal component analysis (PCA) is often used to determine relationships among Operational Taxonomic Units (OTUs) resulting from a clustering analysis, such as USEARCH. I also include variant calling algorithms, such as GATK Haplotype Caller and FreeBayes, in this category, as they make inferences about statistically robust Single Nucleotide Polymorphisms (SNPs) and other variants resulting from mapping reads to a genome or transcriptome.\n"},{"uri":"https://otagomohio.github.io/hacky2021/nesi/nesi_links/","title":"NeSI Links","tags":[],"description":"","content":"The NeSI support page has good documentation for help in getting started and running many tools. This page has some of the most important links. The main page is here:\nNeSI support home page\nInitial set up This page provides guidelines for setting up your computer to access NeSI:\nStandard Terminal Setup\nJob scripts The biggest difference for doing analyses on NeSI versus your own computer is that you need to submit your analysis to a queue, so that the server can handle the demand. The queueing system that NeSI uses is the Slurm system. This entails writing a job script that details the resources you need for each analysis.\nHere is a guide to the basics:\nJob basics\nSLURM Best Practice\nHere is more documentation on the SLURM website:\nSlurm workload manager\nOne of the most important factors to getting your analyses run is to ask for the right resources (i.e. CPUs and RAM). This requires a balance: if you don\u0026rsquo;t ask for enough memory, for example, the job will die; if you ask for too much, the job will sit on the queue for a long time. Here is a guide to finding the right balance:\nFinding job efficiency\nThere are several partitions on NeSI for running analyses. Some are designed for very large jobs. Normally, the queueing system will pick the partition based on the resources you demand, but you can specify a partition. Here is a guide to the Mahuika partitions:\nMahuika Slurm Partitions\nTools on NeSI The job basics link has a guide to using the module command to find the program you need. Here is a list of all currently installed applications:\nSupported applications\nIf you use R for a lot of your data analysis, you probably use RStudio on your own computer. For running R on NeSI, you will have to make some changes. Here is a good article to help that adjustment:\nR on NeSI\nAnother way to run R on NeSI is through the JupyterHub. This is a great way to run Python, R, or other languages on NeSI, and is a good way to start using the server if you are not used to it. Here is a good guide:\nJupyter on NeSI\nAnd here is a direct link to the Hub:\nJupyterHub\nIn the future, RStudio server may be available on NeSI so that you can run large R jobs through NeSI with a familiar interface. Currently there is an experimental version of this, however, it is not in alpha mode and not recommended for beginners. You can read about it here.\n"},{"uri":"https://otagomohio.github.io/hacky2021/basics/transferring_files/","title":"Transferring Files","tags":[],"description":"","content":"Following are some example commands for transferring files and folders to and from the server. The NeSI support page also has good instructions.\nRemember:\n  You must have permissions to access the target folder on the server to which you wish to move your file\n  Your terminal must be on your computer to move files (that is, your pwd should be somewhere on your own computer)\n  Transfer files from your own computer to the server scp /path/to/file/FILENAME mahuika:/path/to/target/folder (Note the colon \u0026lsquo;:\u0026rsquo; after the server name.)\nIf your terminal is in the folder containing the file, you do not need the path:\nscp FILENAME mahuika:/path/to/target/folder Likewise, if you are transferring the file to your home folder on NeSI, then you do not need the path (although remember that your NeSI home folder does not have much space):\nscp FILENAME mahuika: Transferring to a subfolder in your home folder on NeSI:\nscp FILENAME mahuika:scripts/ If the folder is in another part of NeSI, then you need to put the full path:\nscp FILENAME mahuika:/nesi/project/uooXXXX/example_project/example_subfolder/ If you want to upload an entire folder (make sure you want to move all the files), just add the -r argument:\nscp -r /path/to/FOLDERNAME mahuika:/path/to/target/folder Note that this will create a folder called FOLDERNAME within the target folder.\nTransfer files from the server to your own computer In order to move files from NeSI or another server to your own computer, the order of paths is reversed:\nscp mahuika:/path/to/file/FILENAME /path/to/target/folder/ Note if your terminal is in the target folder (pwd), then you can just add a period at the end:\nscp mahuika:/path/to/file/FILENAME . The same rules apply for absolute paths. For example, if you are moving a file from your home folder on NeSI:\nscp mahuika:FILENAME /path/to/target/folder/ You can also substitute the ~ (tilde) for the root path on your computer (e.g. ~/ instead of /Users/hughcross/)\nAnd the same rules apply for downloading folders:\nscp -r mahuika:/nesi/project/uooXXXX/example_project/example_subfolder/ /path/to/target/folder rsync: A better way? You can also use the command line tool rsync to move files to and from the server. It has many uses, such as making regular backups to an external hard drive. rsync has some advantages over using scp, for example, you can update a folder you have already copied to the server, and it will only update the files that have changed (if it is a big folder, this can save lots of time). As well, if the transfer is interrupted, rsync will pick up where it left off. For purposes of archiving, when using rsync, the timestamp of your original files will be preserved, whereas with scp the date of the copied files will be the current one. This can be useful when backing up and preserving the original dates of your files.\nFor a single file\nrsync FILENAME mahuika:/path/to/target/folder It is better to use the -a option, as that will preserve time stamp and permissions, etc. Here I have also added the -v option (\u0026ndash;verbose) which will output the status:\nrsync -av FILENAME mahuika:/path/to/target/folder For syncing folders it is the same command:\nrsync -av /path/to/folder mahuika:/path/to/target/folder And, the same thing transferring from the server to your computer:\nrsync -av mahuika:/path/to/folder ~/Documents If you add the --delete option, any files on the target that are not on the source folder will be deleted. To avoid accidentally deleting any precious files, it is advised to use the --dry-run command first, which will show you what would happen without actually doing anything:\nrsync -av /path/to/source/folder --dry-run --delete scripts mahuika:/path/to/target/folder Once you have checked it will do what you want, you can run without the dry-run option\nrsync -av /path/to/source/folder --delete scripts mahuika:/path/to/target/folder As mentioned, you can do this to back up to an external hard drive:\nrsync -av /path/to/source/folder /Volumes/NAME_OF_EXTERNAL_HD/target/folder "},{"uri":"https://otagomohio.github.io/hacky2021/bugs/troubleshooting/","title":"Troubleshooting errors","tags":[],"description":"","content":"What went wrong? How to spot your mistakes and fix them We have all been there: You have followed all the right steps, have triple-checked the commands, and somehow it doesn’t work; or, you think it works but then the results don\u0026rsquo;t make sense; or, nonsensical error messages seem to scream at you. Next Wednesday we will share some of our own mistakes, errors, FUs, boners, mishaps, catastrophes, and how we fixed them (at least sometimes). And we will try to explain how sometimes even the best designed pipelines don’t survive the first dataset.\nWhy pencils have erasers Here are a few links that list common mistakes in bioinformatics:\nCommon stupid mistakes in bioinformatics\nMore common mistakes in bioinformatics\nHow not to be a bioinformatician\nLinks for getting help The first step that most of us do is google the error message. Sometimes the trick is how to phrase the search. The following websites often come up when you google an error message, but here are the main pages.\nStackoverflow\nSEQanswers\nBiostars\nGoogle Groups and GitHub Two of the best places to keep up on what is going on with a particular program or software package are Google Groups and GitHub. Be sure to check if there is a google group for the software that is giving you problems. Feel free to post your questions; often the developer themself will post an answer and respond to questions. Just do a search on the site to make sure someone else hasn\u0026rsquo;t already had this issue. If the software is on GitHub, then you can check the Issues tab and browse or search there for a similar problem (sometimes googling misses these, depending on how you phrase the search).\nJump back to main Hacky Hour page\n"},{"uri":"https://otagomohio.github.io/hacky2021/basics/","title":"Basics","tags":[],"description":"","content":"basic terminal knowhow \u0026ldquo;The journey of a thousand miles begins with a single step\u0026rdquo;\n-Lao Tzu\n"},{"uri":"https://otagomohio.github.io/hacky2021/nesi/","title":"NeSI","tags":[],"description":"","content":"Using the NeSI server \u0026ldquo;That is the exploration that awaits you!\nNot mapping stars and studying nebula,\nbut charting the unknown possibilities of existence.\u0026quot;\n-Leonard Nimoy\n"},{"uri":"https://otagomohio.github.io/hacky2021/bugs/","title":"Debugging","tags":[],"description":"","content":"How to find and solve common problems \u0026ldquo;Give a man a fish and feed him for a day.\nDon\u0026rsquo;t teach a man to fish and feed yourself.\nHe\u0026rsquo;s a grown man. And fishing\u0026rsquo;s not that hard\u0026rdquo;\n-Ron Swanson\n"},{"uri":"https://otagomohio.github.io/hacky2021/basics/tmux_basics/","title":"Tmux basics","tags":[],"description":"","content":"tmux, or \u0026lsquo;Terminal Multiplexer\u0026rsquo;, is a very useful tool for using the command line. It has many, many tools, but the most important feature for starting out is that you can use it to run programs in the background while you are logged off. That is, you can start a long job, then log out of the server and go home, and tmux will keep the job running. Most of you are familiar with the program screen to accomplish this, but tmux is much more powerful. Below are a few commands to get you started. Once you are used to using it you can begin to explore more options. In the future we will try to keep this page updated with additional tips and tricks, but for now, here is one (of many) cheat sheets available online:\ntmuxcheatsheet.com\nStarting and detaching from a session New Session To start an unnamed session, you can just enter the name of the program at the prompt:\ntmux I suggest you give a session a name when you start it, which will make it easier to keep track once you have multiple sessions going:\ntmux new -s name_of_session Detach from a Session To \u0026lsquo;detach\u0026rsquo; or leave a session, you hold down the Control key and the \u0026lsquo;b\u0026rsquo; keys at the same time, release, then press the \u0026rsquo;d' key:\n\u0026lsquo;\u0026lsquo;\u0026lsquo;bash Ctrl-b d '\u0026rsquo;\u0026rsquo;\nNote that the Control and b key action is referred to as a \u0026lsquo;prefix\u0026rsquo; or \u0026lsquo;chord\u0026rsquo;, depending on the tmux guide. This action can be represented differently in different places. For example, on the link above, it is listed as \u0026ldquo;Ctrl + b d. The prefix starts a lot of actions in tmux, but once you are used to it you will find it is easy.\nGo back to existing session If you have started a big job in tmux, and wish to re-enter it, or \u0026lsquo;attach\u0026rsquo;, it is:\ntmux attach or\ntmux a This will go back to the last session. If you have named your session, you can specify this:\ntmux a -t name_of_session Listing active sessions You can list all your tmux sessions, even if you haven\u0026rsquo;t named them:\ntmux ls Note naming your sessions will make it easier to know which you have. If you haven\u0026rsquo;t named them, then they will be numbered. The names (or numbers) of sessions will be the first item when you list them\nDeleting active sessions If you are finished with the job, and no longer need the session, then you can delete, or \u0026lsquo;kill\u0026rsquo; it:\ntmux kill-session -t name_of_session If you do not specify a name of a session (no -t argument), then tmux will kill the last session made.\n"},{"uri":"https://otagomohio.github.io/hacky2021/nesi/collaboration_server/","title":"Collaboration on NeSI","tags":[],"description":"","content":"The Linux operating system was designed for multiple users, which makes it ideal for a server environment, and allows you to share your scripts and files with your colleagues. Here are some links and quick tips to getting your work going and letting others access your files.\nQuick tip: getting your script running Once you have written your script, in order to run it you have to make it executable. This is accomplished with one simple command:\nchmod a+x To break down the above command: chmod means \u0026lsquo;change mode\u0026rsquo;, and is the main command to change permissions. The a refers to all: that you are giving permission for anyone to use this script; the + is to add a permission, and the x is to make the file executable.\nFor a full explanation of all the permission symbols, see this link\nMaking your script available system wide Once you have your script, you can make it available so the computer can find it anywhere on the system. If you are submitting a job (slurm) script on NeSI, you can add something like the following to the slurm script:\nexport PATH='/nesi/project/uoo5555555/scripts/':$PATH The script should be able to then find the script and run it (don\u0026rsquo;t forget to make it executable).\nSymbolic links If you have a folder that is already in the Path (e.g. /usr/local/bin), you can add a symbolic link that adds the script to the existing path:\nln -s /path/to/file /path/to/symlink Sharing files and folders on the server If you are using NeSI, the server is set up so that anyone on the same project can share files and folders in that project directory. If you need to join a project, go to this link for instructions.\nOn other servers, the defaults may be different, and you will have to change the permissions to add a user to one of your directories. A single command can allow everyone in your group access:\nsudo chmod -R 775 /path/to/directory Now run ls -l to see the change in permissions\nThe only issue is that future files that you create will assign the group to the default for your user account. There are two steps to keep all files written in this directory assigned to the group:\numask 0002 sudo chmod g+s /path/to/directory The umask command is explained in detail here and here, and the special permissions command (chmod g+s) is explained here.\n"},{"uri":"https://otagomohio.github.io/hacky2021/bugs/getting_help/","title":"Getting help","tags":[],"description":"","content":"We would like to increase communication among the group. Of course, you are always free to bring your issues and questions to Hacky Hour, but problems occur at random, often inconvenient times. Therefore we are exploring ways for you to post issues to us, and provide a flexible way for everyone to comment. Some suggested options I have heard include: Slack, Wikis, GitHub, and even Twitter. We can discuss all of these, but for this session we start with GitHub.\nPosting issues on a GitHub repository To post an issue on any GitHub repo, you will need a GitHub account. Once you have that, go to this link:\nHacky Hour Issues\nIt is always good practice to check the existing issues (even closed issues) to see if your problem has been addressed.\nIf you find a post that is relevant, you just click on it, and you can add your own comment to the bottom. You can paste in snippets of code, or add files and links. The comment box is Markdown-compatible, so you can format your text with markdown.\nIf you want to be notified about any changes to this issue, click on Notifications box to the right\nIf there is no relevant issue, then you can start a new issue, just click on the green box labeled New issue. You will then receive an email when anyone responds on this post.\nYou can also post and search issues on Google Groups pages "},{"uri":"https://otagomohio.github.io/hacky2021/concepts/","title":"Concepts","tags":[],"description":"","content":"Basic concepts of bioinformatics \u0026ldquo;Let\u0026rsquo;s be straight here. If we find something we can\u0026rsquo;t understand we like to call it something you can\u0026rsquo;t understand, or indeed pronounce\u0026rdquo;\n-Douglas Adams\n"},{"uri":"https://otagomohio.github.io/hacky2021/basics/regular_expressions/","title":"Regular expressions","tags":[],"description":"","content":"For bioinformatics, it is critical to know how to use at least the basics of regular expressions (regex). There are regex that you use all the time, but most of us will look them up more often than not. Following are some links to online tutorials and cheatsheets to guide you the next time you need to use them (it will probably be sooner than you think!\nTutorials and Cheatsheets RexEgg Tutorial\nRexEgg Cheat Sheets\nRegexOne: an interactive tutorial\nRegular-Expressions.info. The name says it all! Also has links for grep and other languages (see below).\nRyans Tutorials\nA very basic regex cheatsheet\nA more thorough cheatsheet\ngrep: find anything the command line program grep, which stands for global regular expression print, can search files and folders for patterns, which includes regular expressions.\nRegex.info site\nUsing regular expressions in grep\ngrep tutorial\nRyans Tutorial on grep and regex\nIntro to grep\nLinks for other languages RexEgg for Python\nregex.info for Python\nregex for Python cheatsheet\nR documentation for regex\nA fairly comprehensive regex primer for the R language\nRStudio.com regex cheatsheet (pdf)\nFor R tidyverse users, here is a link to R for Data Science chapter section on regex, and here is the stringr package regex page.\n"},{"uri":"https://otagomohio.github.io/hacky2021/basics/shell_scripting_basics/","title":"Shell scripting basics","tags":[],"description":"","content":"Once you move beyond basic shell commands, and the process becomes increasingly complicated, you are going to want the commands into a shell script. There are many good tutorials online to get you started. The Software Carpentry website includes some good tips on their Unix Shell lesson (chapters 5 and 6). As well, Data Carpentry has a good introduction on their lesson: Introduction to the Command Line for Genomics. For the lesson here, we will take you through some basics to get you started.\nSimple script In a text editor, add the following:\n#!/usr/bin/env bash # a first script echo 'Hello World' The first line is called the Shebang, which tells the script where the BASH interpreter is. It is possible to run without this line, but your script may not work in all environments (see Here and Here for more details than you would ever want to know). The next line that starts with the # is a comment, and is ignored by BASH, but can help tell the reader what is going on in the script. The last line just has the command to output \u0026ldquo;Hello World\u0026rdquo; to the screen.\nIn order to run any new shell script, you have to make it executable:\nchmod a+x and now it should run. You just have to do this the first time you run it.\nA little less simple: running other programs The following script fastq2fasta.sh will convert one of our example fastq files to a fasta format\n#!/usr/bin/env bash # running another program with the shell: seqtk # This command will convert the fastq file to a fasta file seqtk seq -A example_data/e4485061.924a.4f09.9d7e.bfefc780d1a8_11_L001_R1_001.fastq \u0026gt; example_data/sample1.fasta Repeating the same command: Looping The above script works fine if we want to just do one file (but then you would hardly need a script for one command for one file), but if we want to do the same command on multiple files, we can set up a for loop:\nShell script: fastq2fasta_loop.sh\n#!/usr/bin/env bash # running another program with the shell: seqtk # This command will convert multiple fastq files to the fasta format cd example_data for fq in *.fastq do seqtk seq -A $fq \u0026gt; $fq\\.fasta done The \\ in the command is called an escape. That is so the program doesn\u0026rsquo;t confuse what variable you are calling.\nPlaying with variables Okay, now we can loop through multiple files and run the same command. The only thing with the above script is that now all of the fasta files end in \u0026ldquo;.fastq.fasta\u0026rdquo;, which doesn\u0026rsquo;t look so nice. We can adjust the variable that the for loop is iterating through to adjust the output name:\nfastq2fasta_loop_rename.sh\n#!/usr/bin/env bash # running another program with the shell: seqtk # This command will convert multiple fastq files to the fasta format cd example_data for fq in *.fastq do sampleName=$(echo $fq | cut -f 1 -d '.') echo $sampleName seqtk seq -A $fq \u0026gt; $sampleName\\.fasta done Looping from a file If we don\u0026rsquo;t want to run all the files in the folder, we can make a list and run the loop from there. One way to do this is a While loop:\nfastq2fasta_while_loop_rename.sh\n#!/usr/bin/env bash # running another program with the shell: seqtk # This command will convert multiple fastq files to the fasta format cd example_data cat fqlist | while read line do sampleName=$(echo $line | cut -f 1 -d '.') echo $sampleName seqtk seq -A $line \u0026gt; $sampleName\\.fasta done We can also take more complicated things from a file, for example a table with old and new names, and use these with our variable slicing to give more sensible names to our files:\nfastq2fasta_loop_newName.sh\n#!/usr/bin/env bash # running another program with the shell: seqtk # This command will convert multiple fastq files to the fasta format cd example_data cat fqTable | while read line do currentName=$(echo \u0026quot;$line\u0026quot; | cut -f 1) newName=$(echo \u0026quot;$line\u0026quot; | cut -f 2) echo $currentName echo $newName seqtk seq -A $currentName \u0026gt; $newName\\.fasta # can also use to just change names: #mv $currentName $newName done Are you jazzed about for loops and want even more speed? We\u0026rsquo;ve got a small guide on how to parallelize these loops\n"},{"uri":"https://otagomohio.github.io/hacky2021/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://otagomohio.github.io/hacky2021/tags/","title":"Tags","tags":[],"description":"","content":""}]